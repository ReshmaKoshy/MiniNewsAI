{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a981bf0",
   "metadata": {},
   "source": [
    "# BART Summarize News Articles\n",
    "\n",
    "This notebook:\n",
    "1) Loads your dataset\n",
    "2) Extracts the `body` text\n",
    "3) Summarizes each article to ~500 words with **facebook/bart-large-cnn**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fa92c2",
   "metadata": {},
   "source": [
    "## 0) Install & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "081e0a37-cdb7-4edc-9756-a021b4998215",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/koshyreshma/.local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# If running locally: uncomment to install\n",
    "# !pip install --upgrade pip\n",
    "# !pip install ray[default] transformers torch accelerate pandas tqdm openai python-dotenv\n",
    "\n",
    "import os\n",
    "import math\n",
    "import json\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Any\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Hugging Face summarization\n",
    "from transformers import pipeline\n",
    "\n",
    "# OpenAI Responses API (modern SDK)\n",
    "from openai import OpenAI\n",
    "\n",
    "# Optional: load .env file if present\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "except Exception:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707ec459",
   "metadata": {},
   "source": [
    "## 1) Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044083c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Path to your CSV\n",
    "CSV_PATH = \"datatset2_NullFilled_fullcontent.csv\" #\"balanced_training_dataset.csv\"  # change if needed\n",
    "\n",
    "# Which column has the article text?\n",
    "TEXT_COLUMN = \"full_content\"  #body # auto-detected from your upload\n",
    "\n",
    "# Which model to use for summarization\n",
    "HF_SUMMARY_MODEL = \"facebook/bart-large-cnn\"\n",
    "\n",
    "# Target ~words for the summary (we'll trim by words after generation)\n",
    "SUMMARY_TARGET_WORDS = 500\n",
    "MAX_NEW_TOKENS = 400\n",
    "MIN_NEW_TOKENS = 300 #150 #300\n",
    "\n",
    "# Batch sizes\n",
    "SUMMARIZE_BATCH = 32   # adjust based on your GPU/CPU/RAM\n",
    "CLASSIFY_BATCH  = 16  # small batches help rate limits\n",
    "\n",
    "# Active learning thresholds\n",
    "MIN_CONFIDENCE_ACCEPT = 0.60   # if max class prob < 0.60 -> needs_review\n",
    "MIN_MARGIN_ACCEPT     = 0.15   # if (top1 - top2) < 0.15 -> needs_review\n",
    "\n",
    "# Output paths\n",
    "OUT_CSV_ALL   = \"labeled_with_summaries.csv\"\n",
    "OUT_CSV_REVIEW = \"needs_review.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac0081c",
   "metadata": {},
   "source": [
    "## 2) Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3fc7c3a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 2882 | Columns: ['Unnamed: 0', 'id', 'category', 'full_content']\n",
      "After cleaning, rows: 2882\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "      <th>full_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Climate</td>\n",
       "      <td>Environmental Defenders Face Harassment, Intim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Weather</td>\n",
       "      <td>Piers, Roxie, and Ryuki rock Pasio with a publ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Weather</td>\n",
       "      <td>It goes without saying that boots are one of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Climate</td>\n",
       "      <td>Giraffes are the world's tallest mammals and a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Music</td>\n",
       "      <td>Sleep disturbances and subsequent fatigue are ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  id category                                       full_content\n",
       "0           0   0  Climate  Environmental Defenders Face Harassment, Intim...\n",
       "1           1   1  Weather  Piers, Roxie, and Ryuki rock Pasio with a publ...\n",
       "2           2   2  Weather  It goes without saying that boots are one of t...\n",
       "3           3   3  Climate  Giraffes are the world's tallest mammals and a...\n",
       "4           4   4    Music  Sleep disturbances and subsequent fatigue are ..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "assert TEXT_COLUMN in df.columns, f\"Column '{TEXT_COLUMN}' not in CSV columns: {df.columns}\"\n",
    "df = df.copy()\n",
    "print(\"Rows:\", len(df), \"| Columns:\", list(df.columns))\n",
    "\n",
    "# Basic cleaning of text\n",
    "def clean_text(x: str) -> str:\n",
    "    if not isinstance(x, str):\n",
    "        return \"\"\n",
    "    return ' '.join(x.split())\n",
    "\n",
    "df[TEXT_COLUMN] = df[TEXT_COLUMN].map(clean_text)\n",
    "df = df[df[TEXT_COLUMN].str.len() > 0].reset_index(drop=True)\n",
    "print(\"After cleaning, rows:\", len(df))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71daffd6",
   "metadata": {},
   "source": [
    "## 3) Summarize to ~500 words with BART\n",
    "We control length by setting a **token** max/min and then trimming by **words** to ~500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00b414b7-2be4-4f46-9311-0492658aff92",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 03:35:10,877\tINFO worker.py:2004 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŸ¢ Ray initialized | GPUs detected: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting summaries:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[36m(BartWorker pid=1378859)\u001b[0m `torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Collecting summaries: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [08:07<00:00, 162.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Done: 2882 rows in 8.12 min\n",
      "                                         summary_500\n",
      "0  Environmental Defenders Face Harassment, Intim...\n",
      "1  Piers, Roxie, and Ryuki rock Pasio with a publ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os, time\n",
    "import math\n",
    "import pandas as pd\n",
    "import torch\n",
    "import ray\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ---------- Worker definition ----------\n",
    "@ray.remote(num_gpus=1)\n",
    "class BartWorker:\n",
    "    def __init__(self, model_name=HF_SUMMARY_MODEL, dtype=\"float16\"):\n",
    "        # Ray sets CUDA_VISIBLE_DEVICES to the assigned GPU automatically.\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        torch_dtype = getattr(torch, dtype) if device == \"cuda\" else torch.float32\n",
    "        self.device = device\n",
    "\n",
    "        self.tok = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "            model_name,\n",
    "            torch_dtype=torch_dtype\n",
    "        ).to(device).eval()\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def summarize_batch(self, texts, max_new_tokens=MAX_NEW_TOKENS,\n",
    "                        min_new_tokens=MIN_NEW_TOKENS, target_words=SUMMARY_TARGET_WORDS):\n",
    "        # Clean + tokenize\n",
    "        texts = [\" \".join(str(t).split()) for t in texts]\n",
    "        inputs = self.tok(\n",
    "            texts,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=1024\n",
    "        ).to(self.device)\n",
    "\n",
    "        outputs = self.model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            min_new_tokens=min_new_tokens,\n",
    "            num_beams=4,\n",
    "            do_sample=False,\n",
    "            length_penalty=1.0,\n",
    "            no_repeat_ngram_size=3,\n",
    "            early_stopping=True\n",
    "        )\n",
    "        dec = [self.tok.decode(o, skip_special_tokens=True) for o in outputs]\n",
    "\n",
    "        # Trim to ~target_words\n",
    "        trimmed = []\n",
    "        for s in dec:\n",
    "            w = s.split()\n",
    "            trimmed.append(\" \".join(w[:target_words]) if len(w) > target_words else s)\n",
    "        return trimmed\n",
    "\n",
    "    def summarize_chunks(self, texts, batch_size=SUMMARIZE_BATCH):\n",
    "        out = []\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            out.extend(self.summarize_batch(texts[i:i+batch_size]))\n",
    "        return out\n",
    "\n",
    "\n",
    "# ---------- Orchestration ----------\n",
    "def ray_summarize_dataframe(df: pd.DataFrame,\n",
    "                            text_col: str = TEXT_COLUMN,\n",
    "                            batch_size: int = SUMMARIZE_BATCH):\n",
    "    assert text_col in df.columns, f\"Missing column: {text_col}\"\n",
    "\n",
    "    # Start Ray (single-node). num_gpus=None â†’ Ray auto-detects.\n",
    "    if not ray.is_initialized():\n",
    "        ray.init(ignore_reinit_error=True)\n",
    "\n",
    "    num_gpus = int(ray.available_resources().get(\"GPU\", 0))\n",
    "    if num_gpus < 1:\n",
    "        raise RuntimeError(\"No GPUs visible to Ray. Check your job allocation / CUDA_VISIBLE_DEVICES.\")\n",
    "\n",
    "    print(f\"ðŸŸ¢ Ray initialized | GPUs detected: {num_gpus}\")\n",
    "\n",
    "    # Create one BartWorker per GPU\n",
    "    workers = [BartWorker.remote() for _ in range(num_gpus)]\n",
    "\n",
    "    # Create many small chunks (more chunks than GPUs keeps all workers busy)\n",
    "    texts = df[text_col].astype(str).tolist()\n",
    "    n = len(texts)\n",
    "    CHUNK_ROWS = batch_size * 32   # each task â‰ˆ 32 inference batches\n",
    "    chunks = [(i, texts[i:i+CHUNK_ROWS]) for i in range(0, n, CHUNK_ROWS)]\n",
    "\n",
    "    # Dispatch chunks round-robin to workers\n",
    "    futures = []\n",
    "    for k, (start_idx, chunk_texts) in enumerate(chunks):\n",
    "        w = workers[k % num_gpus]\n",
    "        futures.append((start_idx, w.summarize_chunks.remote(chunk_texts, batch_size=batch_size)))\n",
    "\n",
    "    # Gather results and place them back by index\n",
    "    out = [None] * n\n",
    "    t0 = time.time()\n",
    "    for start_idx, fut in tqdm(futures, desc=\"Collecting summaries\"):\n",
    "        summaries = ray.get(fut)\n",
    "        out[start_idx:start_idx+len(summaries)] = summaries\n",
    "\n",
    "    print(f\"âœ… Done: {n} rows in {(time.time()-t0)/60:.2f} min\")\n",
    "    return out\n",
    "\n",
    "\n",
    "# ----------- RUN -----------\n",
    "# df: your dataframe already loaded\n",
    "if \"summary_500\" not in df.columns or df[\"summary_500\"].isna().any():\n",
    "    df = df.copy()\n",
    "    df[\"summary_500\"] = ray_summarize_dataframe(df, TEXT_COLUMN, SUMMARIZE_BATCH)\n",
    "else:\n",
    "    print(\"Column 'summary_500' already present, skipping summarization.\")\n",
    "\n",
    "print(df[[\"summary_500\"]].head(2))\n",
    "\n",
    "# When done\n",
    "# ray.shutdown()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "30c9d50e-c97b-4fa1-b542-402ddc5f9e76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# When done\n",
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f74823c-4c66-4267-8908-bb766d438c18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"BART_summarized_dataset.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-2.7",
   "language": "python",
   "name": "pytorch-2.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
